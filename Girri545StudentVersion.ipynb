{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Girri_HW1StudentVersion",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gpalrepo/random_data_scraping/blob/master/Girri545StudentVersion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upCKAd8JB6bO",
        "colab_type": "text"
      },
      "source": [
        "#CIS545 Homework 1: Data Wrangling and Cleaning\n",
        "\n",
        "Hello future data scientists and welcome to CIS 545! In this homework, you will familiarize yourself with Pandas ðŸ¼! The cutest animal and one of the essential libraries for Data Science.\n",
        "\n",
        "This homework will focus on Uber and AirBnB data so that you can put this on your resume and pass those resume buzz word detectors! It will be broken into 3 sections:\n",
        "\n",
        "1. Working with Uber Data\n",
        "\n",
        "2. Working with Airbnb Data\n",
        "\n",
        "3. Working on a merged/joined version of the two (More on this later...)\n",
        "\n",
        "**Note: Before starting, I highly recommend you click on the \"Copy To Drive\" option in the top bar. Once you click on that, make sure you are working on that version of the notebook so that your work is saved** \n",
        "\n",
        "Run the following two cells to setup the notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B8jsqghNLaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip3 install penngrader\n",
        "!pip3 install py_stringsimjoin\n",
        "!pip install python-Levenshtein\n",
        "\n",
        "from penngrader.grader import *\n",
        "\n",
        "#Import neccessary libraries\n",
        "!pip install geocoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from string import ascii_letters\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import time\n",
        "import geocoder\n",
        "import py_stringsimjoin as ssj\n",
        "import py_stringmatching as sm\n",
        "from Levenshtein import distance\n",
        "from difflib import SequenceMatcher\n",
        "import requests\n",
        "from lxml import html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_KXUKCBU9vQ",
        "colab_type": "code",
        "outputId": "de076671-aa38-45ef-ba3a-b4af1ff5be00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "!wget https://cis545hw1data.s3.amazonaws.com/airbnb_data_start.csv\n",
        "!wget https://cis545hw1data.s3.amazonaws.com/airbnb_zipcode.csv\n",
        "!wget https://cis545hw1data.s3.amazonaws.com/uber_data_start.csv\n",
        "!wget https://cis545hw1data.s3.amazonaws.com/zillow_data_start.csv"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-05 23:14:17--  https://cis545hw1data.s3.amazonaws.com/airbnb_data_start.csv\n",
            "Resolving cis545hw1data.s3.amazonaws.com (cis545hw1data.s3.amazonaws.com)... 52.216.229.123\n",
            "Connecting to cis545hw1data.s3.amazonaws.com (cis545hw1data.s3.amazonaws.com)|52.216.229.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4261780 (4.1M) [text/csv]\n",
            "Saving to: â€˜airbnb_data_start.csvâ€™\n",
            "\n",
            "airbnb_data_start.c 100%[===================>]   4.06M  3.20MB/s    in 1.3s    \n",
            "\n",
            "2020-02-05 23:14:20 (3.20 MB/s) - â€˜airbnb_data_start.csvâ€™ saved [4261780/4261780]\n",
            "\n",
            "--2020-02-05 23:14:20--  https://cis545hw1data.s3.amazonaws.com/airbnb_zipcode.csv\n",
            "Resolving cis545hw1data.s3.amazonaws.com (cis545hw1data.s3.amazonaws.com)... 52.216.226.120\n",
            "Connecting to cis545hw1data.s3.amazonaws.com (cis545hw1data.s3.amazonaws.com)|52.216.226.120|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4657 (4.5K) [text/csv]\n",
            "Saving to: â€˜airbnb_zipcode.csvâ€™\n",
            "\n",
            "airbnb_zipcode.csv  100%[===================>]   4.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-02-05 23:14:21 (202 MB/s) - â€˜airbnb_zipcode.csvâ€™ saved [4657/4657]\n",
            "\n",
            "--2020-02-05 23:14:23--  https://cis545hw1data.s3.amazonaws.com/uber_data_start.csv\n",
            "Resolving cis545hw1data.s3.amazonaws.com (cis545hw1data.s3.amazonaws.com)... 52.217.14.60\n",
            "Connecting to cis545hw1data.s3.amazonaws.com (cis545hw1data.s3.amazonaws.com)|52.217.14.60|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1865960 (1.8M) [text/csv]\n",
            "Saving to: â€˜uber_data_start.csvâ€™\n",
            "\n",
            "uber_data_start.csv 100%[===================>]   1.78M  1.64MB/s    in 1.1s    \n",
            "\n",
            "2020-02-05 23:14:25 (1.64 MB/s) - â€˜uber_data_start.csvâ€™ saved [1865960/1865960]\n",
            "\n",
            "--2020-02-05 23:14:25--  https://cis545hw1data.s3.amazonaws.com/zillow_data_start.csv\n",
            "Resolving cis545hw1data.s3.amazonaws.com (cis545hw1data.s3.amazonaws.com)... 52.217.38.92\n",
            "Connecting to cis545hw1data.s3.amazonaws.com (cis545hw1data.s3.amazonaws.com)|52.217.38.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10061011 (9.6M) [text/csv]\n",
            "Saving to: â€˜zillow_data_start.csvâ€™\n",
            "\n",
            "zillow_data_start.c 100%[===================>]   9.59M  5.88MB/s    in 1.6s    \n",
            "\n",
            "2020-02-05 23:14:28 (5.88 MB/s) - â€˜zillow_data_start.csvâ€™ saved [10061011/10061011]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K3-m4JuNh9X",
        "colab_type": "text"
      },
      "source": [
        "#What is Pandas?\n",
        "\n",
        "Pandas are \n",
        "\n",
        "<p align = \"center\">\n",
        "<img src = \"https://thehill.com/sites/default/files/styles/article_full/public/panda_getty.jpg?itok=4ce_5sip\" width= \"600\" align =\"center\"/>\n",
        "\n",
        "<img src = \"https://cff2.earth.com/uploads/2016/09/08101343/giant-panda-bear_1big_stock1.jpg\" width= \"600\" align =\"center\"/>\n",
        "\n",
        "</p>\n",
        "\n",
        "\n",
        "But apart from animals, Pandas is a Python library to aid with data manipulation/analysis. It is built with support from Numpy. Numpy is another Python package/library that provides efficient calculations for matricies and other math problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvihpkXCO-zo",
        "colab_type": "text"
      },
      "source": [
        "Let's also get familiarized with the PennGrader. It was developed by a previous TA, Leonardo Murri. He's a cutie and loves Chipotle. What more could you want? This is him here:\n",
        "\n",
        "<p align = \"center\">\n",
        "<img src = \"https://imgur.com/rNd3gIg.png\" width= \"200\" align =\"center\"/>\n",
        "</p>\n",
        "\n",
        "PennGrader was developed to provide students with instant feedback on their answer. You can submit your answer and know whether it's right or wrong instantly. We then record your most recent answer in our backend database. Let's try it out! Fill in the cell below with your 8-digit Penn ID and then run the following cell to initialize the grader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ucPnPp25tgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PLEASE ENSURE YOUR PENN-ID IS ENTERED CORRECTLY. IF NOT, THE AUTOGRADER WON'T KNOW WHO \n",
        "#TO ASSIGN POINTS TO YOU IN OUR BACKEND\n",
        "STUDENT_ID = 24668551 # YOUR PENN-ID GOES HERE AS AN INTEGER#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8YZ-1NV6Du4",
        "colab_type": "code",
        "outputId": "a3dae821-b616-456a-e819-893070d213ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "grader = PennGrader(homework_id = 'CIS545_Spring_2020_HW1', student_id = STUDENT_ID)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PennGrader initialized with Student ID: 24668551\n",
            "\n",
            "Make sure this correct or we will not be able to store your grade\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MEl5f0lTdpJ",
        "colab_type": "text"
      },
      "source": [
        "Pandas (the animal) are lazy. Their days are made up of eating and sleeping. Just like mine. (1 point)\n",
        "\n",
        "In the following cell, put which panda activity you prefer in lowercase(eating or sleeping)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3idBcMu3TZi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Input activity in all lowercase\n",
        "favorite_activity = \"sleeping\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_8s2HvkUS32",
        "colab_type": "code",
        "outputId": "7c243352-23eb-410d-d9d4-f5ae5c1399c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Run this cell to submit to PennGrader!\n",
        "grader.grade(test_case_id = 'panda_test', answer = favorite_activity)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct! You earned 1/1 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zymOmddn6OPs",
        "colab_type": "text"
      },
      "source": [
        "You just had your first experience with the Penn Grader! For the future questions, once you have completed a question, you can submit your answer to the Penn Grader for immediate feedback. Awesome, right?\n",
        "\n",
        "We will use scores from Penn Grader to determine your grade. You will still need to submit your notebook so we can check for cheating and plagarism. Do not cheat. \n",
        "\n",
        "**Note:** If you run Penn Grader after the due date for any question, your assignment will be marked late, even if you already had full points for the question before the deadline. To remedy this, if you're going to run your notebook after the deadline, either do not run the grading cells, or reinitialize the grader with an empty ID."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5Ay_hRPgLDV",
        "colab_type": "text"
      },
      "source": [
        "#Adding our data so that our code can find it\n",
        "\n",
        "We can't be data scientist without data! We provided code for you to download the data(the \"wget\" cell from earlier). If you go to the view on the left and click files, you should see something similar to the image(plus the airbnb_zipcode.csv)\n",
        "\n",
        "<p align = \"center\">\n",
        "<img src = \"https://imgur.com/dCOO2Xk.png\" width= \"200\" align =\"center\"/>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt_SIy9kUbAC",
        "colab_type": "text"
      },
      "source": [
        "#Part 1: Working with Uber Data\n",
        "\n",
        "Let's first get our Uber data loaded into a Pandas Dataframe.\n",
        "\n",
        "I would recommend looking into pandas' \"read_csv\" functionality:\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
        "\n",
        "Save the dataframe to a variable named: \"uber_df\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWWaROO0Ue0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO\n",
        "\n",
        "uber_df = pd.read_csv(\"uber_data_start.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgZES3hzXJSn",
        "colab_type": "text"
      },
      "source": [
        "Let's visualize the dataframe. In the following cell, type the name of the variable you assigned the dataframe to. It should show the dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogfCNlYlXVQn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "644ff321-2c7e-486f-b8e4-603c1a8e2e46"
      },
      "source": [
        "#TODO\n",
        "\n",
        "uber_df"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>vendor_id</th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>dropoff_datetime</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>day_of_trip</th>\n",
              "      <th>pickup_zip</th>\n",
              "      <th>pickup_borough</th>\n",
              "      <th>dropoff_zip</th>\n",
              "      <th>dropoff_borough</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>id2875421</td>\n",
              "      <td>2</td>\n",
              "      <td>3/14/16 17:24</td>\n",
              "      <td>3/14/16 17:32</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.982155</td>\n",
              "      <td>40.767937</td>\n",
              "      <td>-73.964630</td>\n",
              "      <td>40.765602</td>\n",
              "      <td>Monday</td>\n",
              "      <td>10023</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10065</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>id2377394</td>\n",
              "      <td>1</td>\n",
              "      <td>6/12/16 0:43</td>\n",
              "      <td>6/12/16 0:54</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.980415</td>\n",
              "      <td>40.738564</td>\n",
              "      <td>-73.999481</td>\n",
              "      <td>40.731152</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>10010</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10012</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>id3858529</td>\n",
              "      <td>2</td>\n",
              "      <td>1/19/16 11:35</td>\n",
              "      <td>1/19/16 12:10</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.979027</td>\n",
              "      <td>40.763939</td>\n",
              "      <td>-74.005333</td>\n",
              "      <td>40.710087</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>10019</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10038</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>id3504673</td>\n",
              "      <td>2</td>\n",
              "      <td>4/6/16 19:32</td>\n",
              "      <td>4/6/16 19:39</td>\n",
              "      <td>1</td>\n",
              "      <td>-74.010040</td>\n",
              "      <td>40.719971</td>\n",
              "      <td>-74.012268</td>\n",
              "      <td>40.706718</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>10013</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10004</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>id2181028</td>\n",
              "      <td>2</td>\n",
              "      <td>3/26/16 13:30</td>\n",
              "      <td>3/26/16 13:38</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.973053</td>\n",
              "      <td>40.793209</td>\n",
              "      <td>-73.972923</td>\n",
              "      <td>40.782520</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>10025</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10024</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13647</th>\n",
              "      <td>15045</td>\n",
              "      <td>id1883521</td>\n",
              "      <td>2</td>\n",
              "      <td>1/22/16 16:55</td>\n",
              "      <td>1/22/16 17:13</td>\n",
              "      <td>2</td>\n",
              "      <td>-74.014778</td>\n",
              "      <td>40.709770</td>\n",
              "      <td>-73.982513</td>\n",
              "      <td>40.764381</td>\n",
              "      <td>Friday</td>\n",
              "      <td>10006</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10019</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13648</th>\n",
              "      <td>15047</td>\n",
              "      <td>id0546294</td>\n",
              "      <td>1</td>\n",
              "      <td>3/23/16 13:12</td>\n",
              "      <td>3/23/16 13:19</td>\n",
              "      <td>2</td>\n",
              "      <td>-73.964386</td>\n",
              "      <td>40.773315</td>\n",
              "      <td>-73.955849</td>\n",
              "      <td>40.785049</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>10021</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10128</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13649</th>\n",
              "      <td>15048</td>\n",
              "      <td>id2764754</td>\n",
              "      <td>1</td>\n",
              "      <td>1/7/16 12:48</td>\n",
              "      <td>1/7/16 13:04</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.975426</td>\n",
              "      <td>40.752224</td>\n",
              "      <td>-73.985977</td>\n",
              "      <td>40.755810</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>10017</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10036</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13650</th>\n",
              "      <td>15049</td>\n",
              "      <td>id1811455</td>\n",
              "      <td>2</td>\n",
              "      <td>3/23/16 15:02</td>\n",
              "      <td>3/23/16 15:18</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.953751</td>\n",
              "      <td>40.775089</td>\n",
              "      <td>-73.982193</td>\n",
              "      <td>40.778511</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>10028</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10023</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13651</th>\n",
              "      <td>15050</td>\n",
              "      <td>id1264465</td>\n",
              "      <td>2</td>\n",
              "      <td>4/11/16 11:09</td>\n",
              "      <td>4/11/16 11:24</td>\n",
              "      <td>2</td>\n",
              "      <td>-73.994461</td>\n",
              "      <td>40.765064</td>\n",
              "      <td>-73.976875</td>\n",
              "      <td>40.764553</td>\n",
              "      <td>Monday</td>\n",
              "      <td>10019</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10019</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13652 rows Ã— 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index         id  vendor_id  ... pickup_borough dropoff_zip  dropoff_borough\n",
              "0          0  id2875421          2  ...      Manhattan       10065        Manhattan\n",
              "1          1  id2377394          1  ...      Manhattan       10012        Manhattan\n",
              "2          2  id3858529          2  ...      Manhattan       10038        Manhattan\n",
              "3          3  id3504673          2  ...      Manhattan       10004        Manhattan\n",
              "4          4  id2181028          2  ...      Manhattan       10024        Manhattan\n",
              "...      ...        ...        ...  ...            ...         ...              ...\n",
              "13647  15045  id1883521          2  ...      Manhattan       10019        Manhattan\n",
              "13648  15047  id0546294          1  ...      Manhattan       10128        Manhattan\n",
              "13649  15048  id2764754          1  ...      Manhattan       10036        Manhattan\n",
              "13650  15049  id1811455          2  ...      Manhattan       10023        Manhattan\n",
              "13651  15050  id1264465          2  ...      Manhattan       10019        Manhattan\n",
              "\n",
              "[13652 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTsd4gbgXZoD",
        "colab_type": "text"
      },
      "source": [
        "##1.1 Dropping data\n",
        "\n",
        "When you work with data, you'll have NaNs, duplicates or columns that don't give much insight into the data. There are different ways to deal with missing values (i.e. imputation, which you can read into on your own), but for now, let's drop some of these rows to clean up our data. \n",
        "\n",
        "1. Drop duplicate rows\n",
        "2. Drop rows that have a nan in them\n",
        "3. Drop the \"index\", \"id\", and \"vendor_id\" columns. These columns don't provide much info on our data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_IUqZanYGHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO\n",
        "uber_df.drop_duplicates(inplace=True) ##??Why hasn't it decreased \n",
        "uber_df = uber_df.dropna() ###Maybe do a Nan detection later \n",
        "uber_df.drop(['index', 'id','vendor_id'], axis=1, inplace=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GwTkUYXY4sO",
        "colab_type": "text"
      },
      "source": [
        "Visualize your dataframe again to check if you dropped the columns properly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StmzPy6kYYkn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "62a629b5-2283-4898-87f5-29964d3defd1"
      },
      "source": [
        "#TODO\n",
        "uber_df #SWEET! "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>dropoff_datetime</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>day_of_trip</th>\n",
              "      <th>pickup_zip</th>\n",
              "      <th>pickup_borough</th>\n",
              "      <th>dropoff_zip</th>\n",
              "      <th>dropoff_borough</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3/14/16 17:24</td>\n",
              "      <td>3/14/16 17:32</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.982155</td>\n",
              "      <td>40.767937</td>\n",
              "      <td>-73.964630</td>\n",
              "      <td>40.765602</td>\n",
              "      <td>Monday</td>\n",
              "      <td>10023</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10065</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6/12/16 0:43</td>\n",
              "      <td>6/12/16 0:54</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.980415</td>\n",
              "      <td>40.738564</td>\n",
              "      <td>-73.999481</td>\n",
              "      <td>40.731152</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>10010</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10012</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/19/16 11:35</td>\n",
              "      <td>1/19/16 12:10</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.979027</td>\n",
              "      <td>40.763939</td>\n",
              "      <td>-74.005333</td>\n",
              "      <td>40.710087</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>10019</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10038</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4/6/16 19:32</td>\n",
              "      <td>4/6/16 19:39</td>\n",
              "      <td>1</td>\n",
              "      <td>-74.010040</td>\n",
              "      <td>40.719971</td>\n",
              "      <td>-74.012268</td>\n",
              "      <td>40.706718</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>10013</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10004</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3/26/16 13:30</td>\n",
              "      <td>3/26/16 13:38</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.973053</td>\n",
              "      <td>40.793209</td>\n",
              "      <td>-73.972923</td>\n",
              "      <td>40.782520</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>10025</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10024</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13647</th>\n",
              "      <td>1/22/16 16:55</td>\n",
              "      <td>1/22/16 17:13</td>\n",
              "      <td>2</td>\n",
              "      <td>-74.014778</td>\n",
              "      <td>40.709770</td>\n",
              "      <td>-73.982513</td>\n",
              "      <td>40.764381</td>\n",
              "      <td>Friday</td>\n",
              "      <td>10006</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10019</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13648</th>\n",
              "      <td>3/23/16 13:12</td>\n",
              "      <td>3/23/16 13:19</td>\n",
              "      <td>2</td>\n",
              "      <td>-73.964386</td>\n",
              "      <td>40.773315</td>\n",
              "      <td>-73.955849</td>\n",
              "      <td>40.785049</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>10021</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10128</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13649</th>\n",
              "      <td>1/7/16 12:48</td>\n",
              "      <td>1/7/16 13:04</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.975426</td>\n",
              "      <td>40.752224</td>\n",
              "      <td>-73.985977</td>\n",
              "      <td>40.755810</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>10017</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10036</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13650</th>\n",
              "      <td>3/23/16 15:02</td>\n",
              "      <td>3/23/16 15:18</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.953751</td>\n",
              "      <td>40.775089</td>\n",
              "      <td>-73.982193</td>\n",
              "      <td>40.778511</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>10028</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10023</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13651</th>\n",
              "      <td>4/11/16 11:09</td>\n",
              "      <td>4/11/16 11:24</td>\n",
              "      <td>2</td>\n",
              "      <td>-73.994461</td>\n",
              "      <td>40.765064</td>\n",
              "      <td>-73.976875</td>\n",
              "      <td>40.764553</td>\n",
              "      <td>Monday</td>\n",
              "      <td>10019</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10019</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13652 rows Ã— 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      pickup_datetime dropoff_datetime  ...  dropoff_zip  dropoff_borough\n",
              "0       3/14/16 17:24    3/14/16 17:32  ...        10065        Manhattan\n",
              "1        6/12/16 0:43     6/12/16 0:54  ...        10012        Manhattan\n",
              "2       1/19/16 11:35    1/19/16 12:10  ...        10038        Manhattan\n",
              "3        4/6/16 19:32     4/6/16 19:39  ...        10004        Manhattan\n",
              "4       3/26/16 13:30    3/26/16 13:38  ...        10024        Manhattan\n",
              "...               ...              ...  ...          ...              ...\n",
              "13647   1/22/16 16:55    1/22/16 17:13  ...        10019        Manhattan\n",
              "13648   3/23/16 13:12    3/23/16 13:19  ...        10128        Manhattan\n",
              "13649    1/7/16 12:48     1/7/16 13:04  ...        10036        Manhattan\n",
              "13650   3/23/16 15:02    3/23/16 15:18  ...        10023        Manhattan\n",
              "13651   4/11/16 11:09    4/11/16 11:24  ...        10019        Manhattan\n",
              "\n",
              "[13652 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIlJxXVigr18",
        "colab_type": "text"
      },
      "source": [
        "Pass the cleaned Uber dataframe to the following cell as the input for the \"answer\" parameter (3 point)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyQRhEXsYt3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "da796ef0-7c19-473c-ffc3-8850faad3ca3"
      },
      "source": [
        "#Penn Grader entry\n",
        "#grader.grade(test_case_id = 'uber_drop_test', answer = uber_df)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct! You earned 3/3 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaY5kOL2ZPyK",
        "colab_type": "text"
      },
      "source": [
        "##1.2 Extracting day, month and hour for each uber trip\n",
        "\n",
        "Next, let's filter out information from the pickup_datetime and dropoff_datetime columns. We want to add columns for the month, day and hour the trip occured. \n",
        "\n",
        "Hint: Highly recommend using the \"apply\" function\n",
        "\n",
        "\n",
        "**Give the following names to the columns to represent their values(case sensitive):**\n",
        "\n",
        "**pickup_year,\tpickup_day,\tpickup_month,\tpickup_hour,\tdropoff_year,\tdropoff_day,\tdropoff_month,\tdropoff_hour** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JAKEQ7MZG_g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "d33e8bcb-4c41-42d2-fa22-5715fd067662"
      },
      "source": [
        "#TODO\n",
        "uber_df.head()\n",
        "uber_df['pickup_year'] = uber_df['pickup_datetime'].apply(lambda row: row.split(' ')[0].split('/')[2] )\n",
        "uber_df['pickup_day'] = uber_df['pickup_datetime'].apply(lambda row: row.split(' ')[0].split('/')[1] )\n",
        "uber_df['pickup_month'] = uber_df['pickup_datetime'].apply(lambda row: row.split(' ')[0].split('/')[0] )\n",
        "uber_df['pickup_hour'] = uber_df['pickup_datetime'].apply(lambda row: row.split(' ')[1].split(':')[0] )\n",
        "\n",
        "uber_df['dropoff_year'] = uber_df['dropoff_datetime'].apply(lambda row: row.split(' ')[0].split('/')[2] )\n",
        "uber_df['dropoff_day'] = uber_df['dropoff_datetime'].apply(lambda row: row.split(' ')[0].split('/')[1] )\n",
        "uber_df['dropoff_month'] = uber_df['dropoff_datetime'].apply(lambda row: row.split(' ')[0].split('/')[0] )\n",
        "uber_df['dropoff_hour'] = uber_df['dropoff_datetime'].apply(lambda row: row.split(' ')[1].split(':')[0] )\n",
        "\n",
        "uber_df.head(5)\n",
        "# uber_df['pickup_year'] = uber_df['pickup_datetime'].apply(lambda row: row.strftime('%Y') )\n",
        "#We need a way of splicing the data \n",
        "# df['pickup_year'] = df.apply(lambda row: row.Cost - \n",
        "#                                   (row.Cost * 0.1), axis = 1) \n",
        "#How to know the type of data we have \n",
        "# print(uber_df.dtypes)\n",
        "#df['month_year'] = df['date_column'].dt.to_period('M')\n",
        "#  df['mnth_yr'] = df['date_column'].apply(lambda x: x.strftime('%B-%Y'))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>dropoff_datetime</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>day_of_trip</th>\n",
              "      <th>pickup_zip</th>\n",
              "      <th>pickup_borough</th>\n",
              "      <th>dropoff_zip</th>\n",
              "      <th>dropoff_borough</th>\n",
              "      <th>pickup_year</th>\n",
              "      <th>pickup_day</th>\n",
              "      <th>pickup_month</th>\n",
              "      <th>pickup_hour</th>\n",
              "      <th>dropoff_year</th>\n",
              "      <th>dropoff_day</th>\n",
              "      <th>dropoff_month</th>\n",
              "      <th>dropoff_hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3/14/16 17:24</td>\n",
              "      <td>3/14/16 17:32</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.982155</td>\n",
              "      <td>40.767937</td>\n",
              "      <td>-73.964630</td>\n",
              "      <td>40.765602</td>\n",
              "      <td>Monday</td>\n",
              "      <td>10023</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10065</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6/12/16 0:43</td>\n",
              "      <td>6/12/16 0:54</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.980415</td>\n",
              "      <td>40.738564</td>\n",
              "      <td>-73.999481</td>\n",
              "      <td>40.731152</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>10010</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10012</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/19/16 11:35</td>\n",
              "      <td>1/19/16 12:10</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.979027</td>\n",
              "      <td>40.763939</td>\n",
              "      <td>-74.005333</td>\n",
              "      <td>40.710087</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>10019</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10038</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4/6/16 19:32</td>\n",
              "      <td>4/6/16 19:39</td>\n",
              "      <td>1</td>\n",
              "      <td>-74.010040</td>\n",
              "      <td>40.719971</td>\n",
              "      <td>-74.012268</td>\n",
              "      <td>40.706718</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>10013</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10004</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3/26/16 13:30</td>\n",
              "      <td>3/26/16 13:38</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.973053</td>\n",
              "      <td>40.793209</td>\n",
              "      <td>-73.972923</td>\n",
              "      <td>40.782520</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>10025</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10024</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  pickup_datetime dropoff_datetime  ...  dropoff_month  dropoff_hour\n",
              "0   3/14/16 17:24    3/14/16 17:32  ...              3            17\n",
              "1    6/12/16 0:43     6/12/16 0:54  ...              6             0\n",
              "2   1/19/16 11:35    1/19/16 12:10  ...              1            12\n",
              "3    4/6/16 19:32     4/6/16 19:39  ...              4            19\n",
              "4   3/26/16 13:30    3/26/16 13:38  ...              3            13\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCv-NoAhg49M",
        "colab_type": "text"
      },
      "source": [
        "Pass the cleaned Uber dataframe to the following cell as the input for the \"answer\" parameter (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5xBYSVkoOXj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1a1a2646-317b-44ff-ae4b-84e8b5535aaa"
      },
      "source": [
        "#Penn Grader entry\n",
        "#grader.grade(test_case_id = 'uber_extract', answer = uber_df)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct! You earned 10/10 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVeDP1olq28R",
        "colab_type": "text"
      },
      "source": [
        "Now get the duration of the trip in seconds. I recommend looking into the datetime library in Python. Name this new column: \"seconds\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b4DRhTPp2qZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "#So we can apply across all rows as well so long we specify axis = 1 \n",
        "uber_df['seconds'] = uber_df.apply(lambda row: (datetime.strptime(row['dropoff_datetime'], '%m/%d/%y %H:%M') - datetime.strptime(row['pickup_datetime'], '%m/%d/%y %H:%M')).total_seconds(), axis=1   )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JAfmaEQQbTP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "b47572b3-bf4f-497d-f98b-047453f1d3c8"
      },
      "source": [
        "uber_df"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>dropoff_datetime</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>day_of_trip</th>\n",
              "      <th>pickup_zip</th>\n",
              "      <th>pickup_borough</th>\n",
              "      <th>dropoff_zip</th>\n",
              "      <th>dropoff_borough</th>\n",
              "      <th>pickup_year</th>\n",
              "      <th>pickup_day</th>\n",
              "      <th>pickup_month</th>\n",
              "      <th>pickup_hour</th>\n",
              "      <th>dropoff_year</th>\n",
              "      <th>dropoff_day</th>\n",
              "      <th>dropoff_month</th>\n",
              "      <th>dropoff_hour</th>\n",
              "      <th>seconds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3/14/16 17:24</td>\n",
              "      <td>3/14/16 17:32</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.982155</td>\n",
              "      <td>40.767937</td>\n",
              "      <td>-73.964630</td>\n",
              "      <td>40.765602</td>\n",
              "      <td>Monday</td>\n",
              "      <td>10023</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10065</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6/12/16 0:43</td>\n",
              "      <td>6/12/16 0:54</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.980415</td>\n",
              "      <td>40.738564</td>\n",
              "      <td>-73.999481</td>\n",
              "      <td>40.731152</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>10010</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10012</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>660.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/19/16 11:35</td>\n",
              "      <td>1/19/16 12:10</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.979027</td>\n",
              "      <td>40.763939</td>\n",
              "      <td>-74.005333</td>\n",
              "      <td>40.710087</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>10019</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10038</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>2100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4/6/16 19:32</td>\n",
              "      <td>4/6/16 19:39</td>\n",
              "      <td>1</td>\n",
              "      <td>-74.010040</td>\n",
              "      <td>40.719971</td>\n",
              "      <td>-74.012268</td>\n",
              "      <td>40.706718</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>10013</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10004</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>420.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3/26/16 13:30</td>\n",
              "      <td>3/26/16 13:38</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.973053</td>\n",
              "      <td>40.793209</td>\n",
              "      <td>-73.972923</td>\n",
              "      <td>40.782520</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>10025</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10024</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13647</th>\n",
              "      <td>1/22/16 16:55</td>\n",
              "      <td>1/22/16 17:13</td>\n",
              "      <td>2</td>\n",
              "      <td>-74.014778</td>\n",
              "      <td>40.709770</td>\n",
              "      <td>-73.982513</td>\n",
              "      <td>40.764381</td>\n",
              "      <td>Friday</td>\n",
              "      <td>10006</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10019</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>1080.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13648</th>\n",
              "      <td>3/23/16 13:12</td>\n",
              "      <td>3/23/16 13:19</td>\n",
              "      <td>2</td>\n",
              "      <td>-73.964386</td>\n",
              "      <td>40.773315</td>\n",
              "      <td>-73.955849</td>\n",
              "      <td>40.785049</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>10021</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10128</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>420.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13649</th>\n",
              "      <td>1/7/16 12:48</td>\n",
              "      <td>1/7/16 13:04</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.975426</td>\n",
              "      <td>40.752224</td>\n",
              "      <td>-73.985977</td>\n",
              "      <td>40.755810</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>10017</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10036</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>960.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13650</th>\n",
              "      <td>3/23/16 15:02</td>\n",
              "      <td>3/23/16 15:18</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.953751</td>\n",
              "      <td>40.775089</td>\n",
              "      <td>-73.982193</td>\n",
              "      <td>40.778511</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>10028</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10023</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>960.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13651</th>\n",
              "      <td>4/11/16 11:09</td>\n",
              "      <td>4/11/16 11:24</td>\n",
              "      <td>2</td>\n",
              "      <td>-73.994461</td>\n",
              "      <td>40.765064</td>\n",
              "      <td>-73.976875</td>\n",
              "      <td>40.764553</td>\n",
              "      <td>Monday</td>\n",
              "      <td>10019</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10019</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>900.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13652 rows Ã— 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      pickup_datetime dropoff_datetime  ...  dropoff_hour  seconds\n",
              "0       3/14/16 17:24    3/14/16 17:32  ...            17    480.0\n",
              "1        6/12/16 0:43     6/12/16 0:54  ...             0    660.0\n",
              "2       1/19/16 11:35    1/19/16 12:10  ...            12   2100.0\n",
              "3        4/6/16 19:32     4/6/16 19:39  ...            19    420.0\n",
              "4       3/26/16 13:30    3/26/16 13:38  ...            13    480.0\n",
              "...               ...              ...  ...           ...      ...\n",
              "13647   1/22/16 16:55    1/22/16 17:13  ...            17   1080.0\n",
              "13648   3/23/16 13:12    3/23/16 13:19  ...            13    420.0\n",
              "13649    1/7/16 12:48     1/7/16 13:04  ...            13    960.0\n",
              "13650   3/23/16 15:02    3/23/16 15:18  ...            15    960.0\n",
              "13651   4/11/16 11:09    4/11/16 11:24  ...            11    900.0\n",
              "\n",
              "[13652 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxZG0BYbhCM9",
        "colab_type": "text"
      },
      "source": [
        "Pass the \"seconds\" column(a Series) of the Uber dataframe to the autograder (4 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW_2OT1WsAgy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f168622d-21ae-47bd-a923-a64d9fe44e11"
      },
      "source": [
        "#Penn Grader entry\n",
        "#grader.grade(test_case_id = 'uber_seconds', answer = uber_df['seconds'])"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct! You earned 4/4 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alul5KAyuvZ8",
        "colab_type": "text"
      },
      "source": [
        "Now, find the average uber trip duration in seconds for all trips that are dropped off in Manhattan. Assign your value to the manhattan_duration variable as an int\n",
        "\n",
        "Hint: think split-apply-combine..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnYVA2Sxul3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqMh6xchu-PH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c2374aa-7984-4307-a357-a4cdd5d3497b"
      },
      "source": [
        "manhattan_duration = uber_df.groupby('dropoff_borough')['seconds'].mean()[2]\n",
        "\n",
        "manhattan_duration "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "796.5791352637842"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDk4B30KhKc5",
        "colab_type": "text"
      },
      "source": [
        "Pass the manhattan_duration variable to the autograder (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rznwI-lGwyAd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2126296c-1b39-4b26-d562-0d6823440de7"
      },
      "source": [
        "#Penn grader entry\n",
        "#grader.grade(test_case_id = 'manhattan', answer = manhattan_duration)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct! You earned 5/5 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4LEvxVt01gM",
        "colab_type": "text"
      },
      "source": [
        "##1.3 Find where the cool kids live\n",
        "\n",
        "I'm usually asleep by 11PM but a cool kid is someone whose taking an Uber Friday night and getting dropped off between 12 - 2AM after a fun night of being cool.\n",
        "\n",
        "1. Narrow down your dataframe to rows where the trip happened on a Friday and have a drop off time between 12 - 2AM (inclusive).\n",
        "\n",
        "2. Get a count of how many rows belong to each dropoff_zipcode (This represents the number of trips that are dropped off at each zipcode). Save this as a series to a variable named 'by_zipcode' for grading. Use \"size\" instead of \"count\" for the groupby\n",
        "\n",
        "3. Return the top 3 zipcodes with the highest count zipcodes as a list in descending order of the count. (If zipcode 11111 has 300 rows, 22222 has 100, 33333 has 200, it should be [11111, 33333, 22222]).\n",
        "\n",
        "Name this list as a variable: \"popular_zipcodes\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmKnVIKcwzX_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "665b8b47-8a71-4203-db1d-1caf5ca491c4"
      },
      "source": [
        "#TODO\n",
        "\n",
        "friday_trips = uber_df['day_of_trip'] == 'Friday'\n",
        "\n",
        "drop_off_time_post12 = (uber_df['dropoff_hour'].astype(int)  >=0)\n",
        "drop_off_time_bef3 = (uber_df['dropoff_hour'].astype(int)  < 3)\n",
        "\n",
        "\n",
        "filtered_df = uber_df[friday_trips & drop_off_time_post12 & drop_off_time_bef3]\n",
        "by_zipcode = filtered_df.groupby('dropoff_zip').size()\n",
        "# print(type(by_zipcode))\n",
        "# In[34]: df.sort_values(['job','count'],ascending=False).groupby('job').head(3)\n",
        "\n",
        "# popular_zipcodes = filtered_df.sort_values(['']].groupby('dropoff_zip').size()\n",
        "popular_zipcodes = filtered_df.groupby('dropoff_zip').size().sort_values(ascending=False).head(3)\n",
        "print(popular_zipcodes)\n",
        "print(type(by_zipcode))\n",
        "by_zipcode\n",
        "popular_zipcodes = [10019,10036,10022]\n",
        "popular_zipcodes\n",
        "print(type(by_zipcode))\n",
        "by_zipcode.dtype\n",
        "by_zipcode"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dropoff_zip\n",
            "10019    12\n",
            "10036    11\n",
            "10022    11\n",
            "dtype: int64\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dropoff_zip\n",
              "10001     6\n",
              "10002     6\n",
              "10003     7\n",
              "10005     2\n",
              "10007     1\n",
              "10009     6\n",
              "10010     6\n",
              "10011     7\n",
              "10012     6\n",
              "10013     5\n",
              "10014     8\n",
              "10016     8\n",
              "10017     6\n",
              "10018     3\n",
              "10019    12\n",
              "10021     1\n",
              "10022    11\n",
              "10023     2\n",
              "10024     8\n",
              "10025     3\n",
              "10029     1\n",
              "10030     1\n",
              "10031     3\n",
              "10032     1\n",
              "10033     2\n",
              "10034     1\n",
              "10036    11\n",
              "10037     1\n",
              "10038     2\n",
              "10065     4\n",
              "10075     4\n",
              "10128     1\n",
              "10453     1\n",
              "10457     1\n",
              "10458     1\n",
              "11101     2\n",
              "11102     1\n",
              "11104     1\n",
              "11106     4\n",
              "11201     3\n",
              "11204     1\n",
              "11205     2\n",
              "11206     2\n",
              "11211     5\n",
              "11213     2\n",
              "11215     2\n",
              "11216     2\n",
              "11217     5\n",
              "11220     2\n",
              "11222     3\n",
              "11226     1\n",
              "11231     1\n",
              "11234     1\n",
              "11237     1\n",
              "11238     1\n",
              "11374     1\n",
              "11377     1\n",
              "11385     1\n",
              "11435     1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ADONXahl8fe",
        "colab_type": "text"
      },
      "source": [
        "Pass in a tuple as your answer to the autograder in the form (Series from part 2, list of 3 zipcodes from part 3) (11 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGaFwGU26STh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9d615266-72fb-4a60-8944-d7ae6d9fb0d7"
      },
      "source": [
        "#Penn grader entry\n",
        "#grader.grade(test_case_id = 'not_craig', answer = (by_zipcode, popular_zipcodes))"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct! You earned 11/11 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GARNK9g3x5k",
        "colab_type": "text"
      },
      "source": [
        "## 1.4 Find the popular days to Uber\n",
        "\n",
        "Which days of the week have highest Uber activity? Get the count of Uber Trips per day and then plot a histogram of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thkF6a1Z3y35",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "5a57528f-3bdb-4fe4-8211-63c9268dcb5d"
      },
      "source": [
        "#TODO\n",
        "day = uber_df.groupby('day_of_trip').size()\n",
        "# ??To check if this the way to plot reviews[reviews[\"platform\"] == \"PlayStation 4\"][\"score\"].plot(kind=\"hist\")\n",
        "# uber_df.hist(column='day_of_trip')\n",
        "day.hist()"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0a1100d208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga-8H0juW0ip",
        "colab_type": "text"
      },
      "source": [
        "Assign (hardcode) the least and most popular days to different variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7zrg1hjS1yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "least_popular = \"Monday\"\n",
        "most_popular = \"Saturday\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ghm9lDgonEfR",
        "colab_type": "text"
      },
      "source": [
        "Submit your answer to the autograder as a tuple (least_popular, most_popular) (4 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMNw86uL9jWU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5edc40ec-1297-4343-be3d-7a883d854610"
      },
      "source": [
        "#Penn grader entry\n",
        "grader.grade(test_case_id = 'popularity_histogram', answer = (least_popular, most_popular))"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct! You earned 4/4 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxh3QKx_BLoK",
        "colab_type": "text"
      },
      "source": [
        "#Part 2: Working with Airbnb Data\n",
        "\n",
        "Read in the AirBnB data similar to the Uber data.\n",
        "\n",
        "Assign it to a variable named: \"airbnb_df\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxCE7HNY6wuy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "597c78da-af76-4ead-a553-be1e5bbac9b2"
      },
      "source": [
        "#TODO\n",
        "airbnb_df = pd.read_csv('airbnb_data_start.csv')\n",
        "print(airbnb_df)\n",
        "airbnb_df.drop_duplicates(inplace=True)\n",
        "airbnb_df = airbnb_df.dropna()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          id  ... zipcode\n",
            "0          1  ...   11218\n",
            "1          2  ...   10018\n",
            "2          3  ...   11238\n",
            "3          4  ...   10029\n",
            "4          5  ...   10016\n",
            "...      ...  ...     ...\n",
            "27989  27990  ...   11373\n",
            "27990  27991  ...   10036\n",
            "27991  27992  ...   11237\n",
            "27992  27993  ...   11208\n",
            "27993  27994  ...   10034\n",
            "\n",
            "[27994 rows x 17 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwXjh9zU1aPH",
        "colab_type": "text"
      },
      "source": [
        "Do the same drop check as Uber with the duplicates and NaN values\n",
        "\n",
        "For our test, take the first 75 rows of the cleaned airbnb data, save it to a variable and send that to the autograder. (3 points)\n",
        "\n",
        "Name this 75 row df: \"first_75\"\n",
        "\n",
        "**Make sure that when you grab the first 75 rows, you assign this to a new variable and not overwrite the original airbnb_df**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KkShi2V1C2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "outputId": "153b118a-b153-44c5-ed8f-50f2eeaabfeb"
      },
      "source": [
        "#TODO\n",
        "first_75 = airbnb_df.head(75) #Wonder if there is another method to figure this out \n",
        "first_75"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>host_id</th>\n",
              "      <th>host_name</th>\n",
              "      <th>neighbourhood_group</th>\n",
              "      <th>neighbourhood</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>room_type</th>\n",
              "      <th>price</th>\n",
              "      <th>minimum_nights</th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>last_review</th>\n",
              "      <th>reviews_per_month</th>\n",
              "      <th>calculated_host_listings_count</th>\n",
              "      <th>availability_365</th>\n",
              "      <th>zipcode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Clean &amp; quiet apt home by the park</td>\n",
              "      <td>2787</td>\n",
              "      <td>John</td>\n",
              "      <td>Brooklyn</td>\n",
              "      <td>Kensington</td>\n",
              "      <td>40.64749</td>\n",
              "      <td>-73.97237</td>\n",
              "      <td>single</td>\n",
              "      <td>149</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>10/19/18</td>\n",
              "      <td>0.21</td>\n",
              "      <td>6</td>\n",
              "      <td>365</td>\n",
              "      <td>11218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Skylit Midtown Castle</td>\n",
              "      <td>2845</td>\n",
              "      <td>Jennifer</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Midtown</td>\n",
              "      <td>40.75362</td>\n",
              "      <td>-73.98377</td>\n",
              "      <td>whole</td>\n",
              "      <td>225</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>5/21/19</td>\n",
              "      <td>0.38</td>\n",
              "      <td>2</td>\n",
              "      <td>355</td>\n",
              "      <td>10018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Cozy Entire Floor of Brownstone</td>\n",
              "      <td>4869</td>\n",
              "      <td>LisaRoxanne</td>\n",
              "      <td>Brooklyn</td>\n",
              "      <td>Clinton Hill</td>\n",
              "      <td>40.68514</td>\n",
              "      <td>-73.95976</td>\n",
              "      <td>whole</td>\n",
              "      <td>89</td>\n",
              "      <td>1</td>\n",
              "      <td>270</td>\n",
              "      <td>7/5/19</td>\n",
              "      <td>4.64</td>\n",
              "      <td>1</td>\n",
              "      <td>194</td>\n",
              "      <td>11238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
              "      <td>7192</td>\n",
              "      <td>Laura</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>East Harlem</td>\n",
              "      <td>40.79851</td>\n",
              "      <td>-73.94399</td>\n",
              "      <td>whole</td>\n",
              "      <td>80</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>11/19/18</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Large Cozy 1 BR Apartment In Midtown East</td>\n",
              "      <td>7322</td>\n",
              "      <td>Chris</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Murray Hill</td>\n",
              "      <td>40.74767</td>\n",
              "      <td>-73.97500</td>\n",
              "      <td>whole</td>\n",
              "      <td>200</td>\n",
              "      <td>3</td>\n",
              "      <td>74</td>\n",
              "      <td>6/22/19</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1</td>\n",
              "      <td>129</td>\n",
              "      <td>10016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>71</td>\n",
              "      <td>Charming East Village One Bedroom Flat</td>\n",
              "      <td>69829</td>\n",
              "      <td>Josh</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>East Village</td>\n",
              "      <td>40.72828</td>\n",
              "      <td>-73.98801</td>\n",
              "      <td>whole</td>\n",
              "      <td>190</td>\n",
              "      <td>5</td>\n",
              "      <td>21</td>\n",
              "      <td>1/2/19</td>\n",
              "      <td>0.20</td>\n",
              "      <td>1</td>\n",
              "      <td>224</td>\n",
              "      <td>10003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>72</td>\n",
              "      <td>Manhattan Room</td>\n",
              "      <td>69942</td>\n",
              "      <td>Victoria</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Upper East Side</td>\n",
              "      <td>40.76865</td>\n",
              "      <td>-73.95058</td>\n",
              "      <td>single</td>\n",
              "      <td>200</td>\n",
              "      <td>1</td>\n",
              "      <td>142</td>\n",
              "      <td>7/6/19</td>\n",
              "      <td>1.50</td>\n",
              "      <td>1</td>\n",
              "      <td>322</td>\n",
              "      <td>10021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>73</td>\n",
              "      <td>Little King of Queens</td>\n",
              "      <td>70091</td>\n",
              "      <td>Justin</td>\n",
              "      <td>Queens</td>\n",
              "      <td>Woodside</td>\n",
              "      <td>40.75038</td>\n",
              "      <td>-73.90334</td>\n",
              "      <td>single</td>\n",
              "      <td>70</td>\n",
              "      <td>30</td>\n",
              "      <td>25</td>\n",
              "      <td>5/31/19</td>\n",
              "      <td>0.22</td>\n",
              "      <td>1</td>\n",
              "      <td>324</td>\n",
              "      <td>11377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>74</td>\n",
              "      <td>Fort Greene Retreat on the Park</td>\n",
              "      <td>71512</td>\n",
              "      <td>Blaise</td>\n",
              "      <td>Brooklyn</td>\n",
              "      <td>Fort Greene</td>\n",
              "      <td>40.69320</td>\n",
              "      <td>-73.97267</td>\n",
              "      <td>single</td>\n",
              "      <td>95</td>\n",
              "      <td>3</td>\n",
              "      <td>143</td>\n",
              "      <td>6/16/19</td>\n",
              "      <td>1.28</td>\n",
              "      <td>1</td>\n",
              "      <td>132</td>\n",
              "      <td>11205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>75</td>\n",
              "      <td>Beautiful Meatpacking District Loft</td>\n",
              "      <td>71876</td>\n",
              "      <td>DAVID And RICK</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Chelsea</td>\n",
              "      <td>40.74138</td>\n",
              "      <td>-74.00197</td>\n",
              "      <td>single</td>\n",
              "      <td>150</td>\n",
              "      <td>3</td>\n",
              "      <td>167</td>\n",
              "      <td>5/28/19</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1</td>\n",
              "      <td>295</td>\n",
              "      <td>10011</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75 rows Ã— 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  ... zipcode\n",
              "0    1  ...   11218\n",
              "1    2  ...   10018\n",
              "2    3  ...   11238\n",
              "3    4  ...   10029\n",
              "4    5  ...   10016\n",
              "..  ..  ...     ...\n",
              "70  71  ...   10003\n",
              "71  72  ...   10021\n",
              "72  73  ...   11377\n",
              "73  74  ...   11205\n",
              "74  75  ...   10011\n",
              "\n",
              "[75 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxYCbk1Y17Jz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8797ea1a-9b76-4ec0-bab3-e0ed8494918a"
      },
      "source": [
        "#Penn grader entry\n",
        "#grader.grade(test_case_id = 'airbnb_drop', answer = first_75)"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct! You earned 3/3 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0lbc-EJ2gop",
        "colab_type": "text"
      },
      "source": [
        "Nobody wants to stay in an AirBnB that has very few ratings. Seems very sketchy. Let's drop all the rows/listings that have less than 5 reviews.\n",
        "\n",
        "Save this to a variable named: \"airbnb_review_5_df\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N90ACUHK2EBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO\n",
        "# drop_off_time_post12 = (uber_df['dropoff_hour'].astype(int)  >=0)\n",
        "\n",
        "less_than_five = (airbnb_df['number_of_reviews'].astype(int) >= 5)\n",
        "airbnb_review_5_df = airbnb_df[less_than_five]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1HbxHCznTjA",
        "colab_type": "text"
      },
      "source": [
        "Pass in the filtered dataframe into the autograder (3 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RFQEwST2wst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Penn grader entry\n",
        "# grader.grade(test_case_id = 'airbnb_filter', answer = airbnb_review_5_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPl8bysR0hZc",
        "colab_type": "text"
      },
      "source": [
        "###2.1 Get more data that you don't already have\n",
        "\n",
        "In this case, we gave you a CSV that had zipcodes for AirBnbs. However, in the real world, you'll need to add additional data to your existing data. That's what we'll do here.\n",
        "\n",
        "Read in airbnb_zipcode.csv into a dataframe and delete the columns that have NaN. You'll notice this data doesn't have a zipcode column. We want the zipcode for each row. Add a new column to the dataframe with the associated zipcode for the given longitude/latitude point. This can be achieved through using the latitude and longitude. Google around for ways to convert latitude/longitude points into a zipcode in Python. I suggest a few options:\n",
        "\n",
        "* https://geopy.readthedocs.io/en/stable/\n",
        "\n",
        "* https://developer.mapquest.com/\n",
        "\n",
        "* https://stackoverflow.com/questions/54320931/python-code-for-reverse-geo-coding-using-google-api\n",
        "\n",
        "This part can be a little challenging. Keep working at it and don't get discouraged! We believe in you. TAs are also here to help (office hours & Piazza)!\n",
        "\n",
        "**Make sure the added zipcode column name is named \"zipcode\"**\n",
        "\n",
        "Name the variable that you read in the data as: \"airbnb_zip\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpkmijqsLgrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests #Done! "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8dem8BGLaEs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9c156c7d-50c1-4236-c2ee-b176219115e1"
      },
      "source": [
        "#Creation of function to extract zipcode \n",
        "key= \"DHju1AlckFxE7V8A6leCt2KNmZ6HklxF\"\n",
        "endpoint = f\"http://www.mapquestapi.com/geocoding/v1/reverse?key={key}&location={long},{lat}&includeRoadMetadata=true&includeNearestIntersection=true\"\n",
        "r = requests.get(endpoint)\n",
        "print(r)\n",
        "results = r.json()['results'][0]['locations'][0]['postalCode']\n",
        "results\n"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Response [200]>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'32225'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUhTb_6L0-7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO\n",
        "airbnb_zip = pd.read_csv('airbnb_zipcode.csv')\n",
        "airbnb_zip.dropna(axis=1, inplace= True)\n",
        "# airbnb_zip = \"\"\n",
        "airbnb_zip "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa3yoorlLZb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Waa5nGD2zR5",
        "colab_type": "text"
      },
      "source": [
        "Depending on the method you used to obtain the zipcode, you might have rows with a zipcode that look like \"11216-2813\". We only care about what's before the \"-\". If a row already has a zipcode that is only 5 numbers (i.e. 11216), then we want to leave it how it is.\n",
        "\n",
        "Fix your dataframe from the previous step so that the zipcode column only has the 5 numbers for each zipcode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxO3SHXnWAxV",
        "colab_type": "text"
      },
      "source": [
        "For our test, make sure the zipcode column is all ints. Once you make sure that the zipcode column is ints, submit the newly made dataframe with the extra zipcode column. Double check that you named the extra column what we want it to be. (13 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFkwimb53hUW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4db08ed4-d778-43f3-82be-d5304ea846bb"
      },
      "source": [
        "#Penn grader entry\n",
        "grader.grade(test_case_id = 'airbnb_zip', answer = airbnb_zip)"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error: Test case failed. Test case function could not complete due to an error in your answer.\n",
            "Error Hint: 'zipcode'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh4pp5Nd3Wx3",
        "colab_type": "text"
      },
      "source": [
        "#Part 3: Combining the data\n",
        "\n",
        "When you become a full time data scientist, a lot of times, data will be spread out across multiple files/tables. The way to combine these tables is through join/merge operations. If you're familiar with SQL, this will be very familiar to you. If not, don't worry. I believe in you!\n",
        "\n",
        "To start, here's a nice diagram which shows you the different types of joins\n",
        "\n",
        "\n",
        "<p align = \"center\">\n",
        "<img src = \"https://i.stack.imgur.com/hMKKt.jpg\" width= \"600\" align =\"center\"/>\n",
        "</p>\n",
        "\n",
        "A clarifying point: The two venn diagrams with the \"(if Null)\" are also called Left Outer Join and Right Outer Join\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DitIiPoGXhUW",
        "colab_type": "text"
      },
      "source": [
        "Now, we want all the zipcodes that don't appear in both datasets (If 11111 is in uber data and airbnb data, we don't want it. If 22222 is in uber data but not in airbnb, we want to keep it. If 33333 is in airbnb data but not in uber, we want to keep it). In other words, we want all the zipcodes that have airbnbs where an Uber has never dropped someone off at those zipcodes and all Ubers that have dropped people off at zipcodes where no AirBnB exists (this is probably impossible in the real world, but our data is a small sample of the real world). \n",
        "\n",
        "Hint: Google around for Exclusive Full Joins\n",
        "\n",
        "We want the final answer as a two column dataframe with columns named: uber_zips, airbnb_zips. Uber_zips should contain the zipcodes that only exist within the uber dataset and vice-a-versa for airbnb_zips column. To clarify, this means if there is a row where airbnb_zip has a zipcode, that same row should not have an uber_zip entry(Should be NaN) as otherwise, that means that zipcode is shared between both datasets\n",
        "\n",
        "Make sure your final answer dataframe is named: \"combined_df\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f0J7ycln-A_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "cf6e6ea8-dac8-41e7-d994-fdcc31e24e3c"
      },
      "source": [
        "uber_df"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>dropoff_datetime</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>day_of_trip</th>\n",
              "      <th>pickup_zip</th>\n",
              "      <th>pickup_borough</th>\n",
              "      <th>dropoff_zip</th>\n",
              "      <th>dropoff_borough</th>\n",
              "      <th>pickup_year</th>\n",
              "      <th>pickup_day</th>\n",
              "      <th>pickup_month</th>\n",
              "      <th>pickup_hour</th>\n",
              "      <th>dropoff_year</th>\n",
              "      <th>dropoff_day</th>\n",
              "      <th>dropoff_month</th>\n",
              "      <th>dropoff_hour</th>\n",
              "      <th>seconds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3/14/16 17:24</td>\n",
              "      <td>3/14/16 17:32</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.982155</td>\n",
              "      <td>40.767937</td>\n",
              "      <td>-73.964630</td>\n",
              "      <td>40.765602</td>\n",
              "      <td>Monday</td>\n",
              "      <td>10023</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10065</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6/12/16 0:43</td>\n",
              "      <td>6/12/16 0:54</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.980415</td>\n",
              "      <td>40.738564</td>\n",
              "      <td>-73.999481</td>\n",
              "      <td>40.731152</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>10010</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10012</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>660.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/19/16 11:35</td>\n",
              "      <td>1/19/16 12:10</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.979027</td>\n",
              "      <td>40.763939</td>\n",
              "      <td>-74.005333</td>\n",
              "      <td>40.710087</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>10019</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10038</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>2100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4/6/16 19:32</td>\n",
              "      <td>4/6/16 19:39</td>\n",
              "      <td>1</td>\n",
              "      <td>-74.010040</td>\n",
              "      <td>40.719971</td>\n",
              "      <td>-74.012268</td>\n",
              "      <td>40.706718</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>10013</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10004</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>420.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3/26/16 13:30</td>\n",
              "      <td>3/26/16 13:38</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.973053</td>\n",
              "      <td>40.793209</td>\n",
              "      <td>-73.972923</td>\n",
              "      <td>40.782520</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>10025</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10024</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13647</th>\n",
              "      <td>1/22/16 16:55</td>\n",
              "      <td>1/22/16 17:13</td>\n",
              "      <td>2</td>\n",
              "      <td>-74.014778</td>\n",
              "      <td>40.709770</td>\n",
              "      <td>-73.982513</td>\n",
              "      <td>40.764381</td>\n",
              "      <td>Friday</td>\n",
              "      <td>10006</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10019</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>1080.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13648</th>\n",
              "      <td>3/23/16 13:12</td>\n",
              "      <td>3/23/16 13:19</td>\n",
              "      <td>2</td>\n",
              "      <td>-73.964386</td>\n",
              "      <td>40.773315</td>\n",
              "      <td>-73.955849</td>\n",
              "      <td>40.785049</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>10021</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10128</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>420.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13649</th>\n",
              "      <td>1/7/16 12:48</td>\n",
              "      <td>1/7/16 13:04</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.975426</td>\n",
              "      <td>40.752224</td>\n",
              "      <td>-73.985977</td>\n",
              "      <td>40.755810</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>10017</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10036</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>960.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13650</th>\n",
              "      <td>3/23/16 15:02</td>\n",
              "      <td>3/23/16 15:18</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.953751</td>\n",
              "      <td>40.775089</td>\n",
              "      <td>-73.982193</td>\n",
              "      <td>40.778511</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>10028</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10023</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>960.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13651</th>\n",
              "      <td>4/11/16 11:09</td>\n",
              "      <td>4/11/16 11:24</td>\n",
              "      <td>2</td>\n",
              "      <td>-73.994461</td>\n",
              "      <td>40.765064</td>\n",
              "      <td>-73.976875</td>\n",
              "      <td>40.764553</td>\n",
              "      <td>Monday</td>\n",
              "      <td>10019</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>10019</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>900.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13652 rows Ã— 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      pickup_datetime dropoff_datetime  ...  dropoff_hour  seconds\n",
              "0       3/14/16 17:24    3/14/16 17:32  ...            17    480.0\n",
              "1        6/12/16 0:43     6/12/16 0:54  ...             0    660.0\n",
              "2       1/19/16 11:35    1/19/16 12:10  ...            12   2100.0\n",
              "3        4/6/16 19:32     4/6/16 19:39  ...            19    420.0\n",
              "4       3/26/16 13:30    3/26/16 13:38  ...            13    480.0\n",
              "...               ...              ...  ...           ...      ...\n",
              "13647   1/22/16 16:55    1/22/16 17:13  ...            17   1080.0\n",
              "13648   3/23/16 13:12    3/23/16 13:19  ...            13    420.0\n",
              "13649    1/7/16 12:48     1/7/16 13:04  ...            13    960.0\n",
              "13650   3/23/16 15:02    3/23/16 15:18  ...            15    960.0\n",
              "13651   4/11/16 11:09    4/11/16 11:24  ...            11    900.0\n",
              "\n",
              "[13652 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYatJp7q2xlu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "adc3a216-6474-4c1f-db7a-504b81439bce"
      },
      "source": [
        "#TODO\n",
        "\n",
        "#df1.merge(df2, left_on='lkey', right_on='rkey')\n",
        "#combined_df = \"\"\n",
        "inner_merge = uber_df.merge(airbnb_df, how='inner', left_on='dropoff_zip', right_on='zipcode')['dropoff_zip']\n",
        "type(inner_merge)\n",
        "just_uber = uber_df['dropoff_zip']\n",
        "#just_uber\n",
        "just_airbnb = airbnb_df['zipcode']\n",
        "\n",
        "x = [1,2,3,4]\n",
        "f = [1,11,22,33,44,3,4]\n",
        "s = pd.Series(just_uber,\n",
        "              name=\"uber_zips\")\n",
        "d = pd.Series(just_airbnb, name=\"airbnb_zips\")\n",
        "final = pd.concat([s,d], axis=1)\n",
        "\n",
        "\n",
        "final\n",
        "combined_df = final\n",
        "inner_merge"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          10065\n",
              "1          10065\n",
              "2          10065\n",
              "3          10065\n",
              "4          10065\n",
              "           ...  \n",
              "4885871    11204\n",
              "4885872    11204\n",
              "4885873    11204\n",
              "4885874    11204\n",
              "4885875    11204\n",
              "Name: dropoff_zip, Length: 4885876, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6ZbXLORaBeC",
        "colab_type": "text"
      },
      "source": [
        "Submit the above specified 2 column dataframe to the autograder (12 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqp-zo9GZPzo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "69ee3b32-08d2-4778-93ea-038cae4b8dcd"
      },
      "source": [
        "#grader.grade(test_case_id = 'join_test', answer = combined_df)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct! You earned 12/12 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVuQYQlCaczc",
        "colab_type": "text"
      },
      "source": [
        "#Part 4: Exploring AirBnBs and Zillow\n",
        "\n",
        "Read in the Zillow CSV into a dataframe. If you view the dataframe, you might notice that this csv/dataframe has a lot more NaNs than the AirBnb/Uber data. Soooo let's do the same thing we did with AirBnB and Uber and drop the NaNs and duplicates.\n",
        "\n",
        "Name the dataframe: zillow_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmz6vRcPagfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO\n",
        "zillow_df = pd.read_csv('zillow_data_start.csv')\n",
        "zillow_df = zillow_df.dropna()\n",
        "# airbnb_df.drop_duplicates(inplace=True)\n",
        "# airbnb_df = airbnb_df.dropna()\n",
        "#zillow_df = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkXtLkkqodxx",
        "colab_type": "text"
      },
      "source": [
        "Submit the cleaned zillow dataframe to the autograder (3 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oiHjRzbaqM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "24e768bb-046b-4ae5-a9cf-f23e11231917"
      },
      "source": [
        "#Penn Grader entry\n",
        "grader.grade(test_case_id = 'zillow_drop', answer = zillow_df)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct! You earned 3/3 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNAeU-oabPqx",
        "colab_type": "text"
      },
      "source": [
        "##4.1 Correlation Matrix\n",
        "\n",
        "We want to see if, on average, there is any correlation between the gross square footage of apartments versus airbnb prices for shared zipcodes, and if there is a correlation, how strong is it?\n",
        "\n",
        "This can be broken into several steps:\n",
        "\n",
        "1. Find the average value of each column for each zipcode within Zillow\n",
        "\n",
        "2. Find the average value of each column for each zipcode within AirBnb\n",
        "\n",
        "3. Merge them on the matching column.\n",
        "  Your merged table now has 3 nonsense columns. That is, since the values have been averaged by zipcode, these columns no longer include valid information... think on it and visit office hours if you get stuck! Identify and drop these (can also be done in steps 1 and 2).\n",
        "\n",
        "4. Generate the correlation matrix. Find the value associated with Zillow Gross Square footage vs Airbnb Price\n",
        "\n",
        "Hint: Read about Pandas \"corr()\" function.\n",
        "\n",
        "**You can correctly answer the following section just using Zillow's gross square footage column and Airbnb's price column but after this question, we want to plot a correlation matrix which will require all the columns(not just the two listed above)**\n",
        "\n",
        "Name your final answer correlation matrix dataframe to: \"correlation_matrix\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aYhg_ypdSsk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "9598f0fe-ce29-498a-a25c-4fdbeb65af81"
      },
      "source": [
        "#TODO\n",
        "correlation_matrix = \"\"\n",
        "zillow_grouped = zillow_df.groupby(['ZIPCODE'], as_index=False).mean()\n",
        "airbnb_grouped = airbnb_df.groupby(['zipcode'], as_index = False).mean()\n",
        "# zillow_df.groupby('ZIPCODE').mean()\n",
        "# >>> g = dfalph[['token', 'year', 'uses', 'books']].groupby(['token', 'year'], as_index=False).sum()\n",
        "# inner_merge = uber_df.merge(airbnb_df, how='inner', left_on='dropoff_zip', right_on='zipcode')\n",
        "\n",
        "merged = zillow_grouped.merge(airbnb_grouped, how='inner', left_on = 'ZIPCODE', right_on = 'zipcode')\n",
        "\n",
        "# merged\n",
        "\n",
        "# zillow_grouped.set_index('id')\n",
        "# airbnb_grouped = airbnb_grouped.set_index('id')\n",
        "# airbnb_grouped['zipcode'] = airbnb_grouped.index\n",
        "# airbnb_grouped['index1'] = airbnb_grouped.index\n",
        "\n",
        "# zillow_grouped.dtypes\n",
        "# airbnb_grouped.dtypes\n",
        "# airbnb_grouped\n",
        "print(type(airbnb_grouped))\n",
        "# print(zillow_grouped.columns)\n",
        "merged\n",
        "##Remove Hosid, ids#"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ZIPCODE</th>\n",
              "      <th>BLOCK</th>\n",
              "      <th>LOT</th>\n",
              "      <th>LAND_SQUARE_FEET</th>\n",
              "      <th>GROSS_SQUARE_FEET</th>\n",
              "      <th>YEAR_BUILT</th>\n",
              "      <th>SALE_PRICE</th>\n",
              "      <th>id_x</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>id_y</th>\n",
              "      <th>host_id</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>price</th>\n",
              "      <th>minimum_nights</th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>reviews_per_month</th>\n",
              "      <th>calculated_host_listings_count</th>\n",
              "      <th>availability_365</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10001.0</td>\n",
              "      <td>786.227273</td>\n",
              "      <td>43.636364</td>\n",
              "      <td>9526.863636</td>\n",
              "      <td>119004.181818</td>\n",
              "      <td>1932.000000</td>\n",
              "      <td>9.468967e+07</td>\n",
              "      <td>2624.863636</td>\n",
              "      <td>10001</td>\n",
              "      <td>14821.403774</td>\n",
              "      <td>5.182550e+07</td>\n",
              "      <td>40.748760</td>\n",
              "      <td>-73.994321</td>\n",
              "      <td>198.139623</td>\n",
              "      <td>12.230189</td>\n",
              "      <td>40.943396</td>\n",
              "      <td>1.274075</td>\n",
              "      <td>8.490566</td>\n",
              "      <td>131.898113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10002.0</td>\n",
              "      <td>354.862069</td>\n",
              "      <td>28.275862</td>\n",
              "      <td>2753.137931</td>\n",
              "      <td>13128.965517</td>\n",
              "      <td>1925.068966</td>\n",
              "      <td>1.250424e+07</td>\n",
              "      <td>6500.551724</td>\n",
              "      <td>10002</td>\n",
              "      <td>13026.979798</td>\n",
              "      <td>3.088338e+07</td>\n",
              "      <td>40.717655</td>\n",
              "      <td>-73.989143</td>\n",
              "      <td>167.304293</td>\n",
              "      <td>5.795455</td>\n",
              "      <td>39.719697</td>\n",
              "      <td>1.044533</td>\n",
              "      <td>1.789141</td>\n",
              "      <td>86.381313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10003.0</td>\n",
              "      <td>684.312500</td>\n",
              "      <td>27.093750</td>\n",
              "      <td>3328.843750</td>\n",
              "      <td>18904.281250</td>\n",
              "      <td>1911.093750</td>\n",
              "      <td>1.583638e+07</td>\n",
              "      <td>3490.906250</td>\n",
              "      <td>10003</td>\n",
              "      <td>12539.996965</td>\n",
              "      <td>2.972121e+07</td>\n",
              "      <td>40.730413</td>\n",
              "      <td>-73.987563</td>\n",
              "      <td>204.462822</td>\n",
              "      <td>6.707132</td>\n",
              "      <td>33.191199</td>\n",
              "      <td>0.860941</td>\n",
              "      <td>3.068285</td>\n",
              "      <td>78.286798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10004.0</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>24798.000000</td>\n",
              "      <td>568649.500000</td>\n",
              "      <td>1995.000000</td>\n",
              "      <td>3.760536e+08</td>\n",
              "      <td>2561.500000</td>\n",
              "      <td>10004</td>\n",
              "      <td>15162.172414</td>\n",
              "      <td>4.209238e+07</td>\n",
              "      <td>40.704774</td>\n",
              "      <td>-74.012068</td>\n",
              "      <td>171.310345</td>\n",
              "      <td>5.517241</td>\n",
              "      <td>25.655172</td>\n",
              "      <td>0.841379</td>\n",
              "      <td>4.448276</td>\n",
              "      <td>92.517241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10005.0</td>\n",
              "      <td>34.400000</td>\n",
              "      <td>12.400000</td>\n",
              "      <td>23495.800000</td>\n",
              "      <td>601447.400000</td>\n",
              "      <td>1942.400000</td>\n",
              "      <td>3.116688e+08</td>\n",
              "      <td>2373.800000</td>\n",
              "      <td>10005</td>\n",
              "      <td>16744.766234</td>\n",
              "      <td>4.781290e+07</td>\n",
              "      <td>40.705570</td>\n",
              "      <td>-74.008431</td>\n",
              "      <td>182.727273</td>\n",
              "      <td>9.961039</td>\n",
              "      <td>22.025974</td>\n",
              "      <td>0.865195</td>\n",
              "      <td>23.662338</td>\n",
              "      <td>138.636364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>11436.0</td>\n",
              "      <td>12034.017094</td>\n",
              "      <td>64.594017</td>\n",
              "      <td>3023.239316</td>\n",
              "      <td>2309.628205</td>\n",
              "      <td>1933.500000</td>\n",
              "      <td>6.500512e+05</td>\n",
              "      <td>71913.636752</td>\n",
              "      <td>11436</td>\n",
              "      <td>19287.266667</td>\n",
              "      <td>8.598197e+07</td>\n",
              "      <td>40.676083</td>\n",
              "      <td>-73.794639</td>\n",
              "      <td>65.133333</td>\n",
              "      <td>1.866667</td>\n",
              "      <td>118.133333</td>\n",
              "      <td>4.140667</td>\n",
              "      <td>1.733333</td>\n",
              "      <td>167.866667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>11691.0</td>\n",
              "      <td>15704.149606</td>\n",
              "      <td>52.740157</td>\n",
              "      <td>4380.893701</td>\n",
              "      <td>2563.980315</td>\n",
              "      <td>1956.346457</td>\n",
              "      <td>4.952071e+05</td>\n",
              "      <td>55093.531496</td>\n",
              "      <td>11691</td>\n",
              "      <td>16662.565217</td>\n",
              "      <td>7.691126e+07</td>\n",
              "      <td>40.597641</td>\n",
              "      <td>-73.760546</td>\n",
              "      <td>78.913043</td>\n",
              "      <td>8.304348</td>\n",
              "      <td>21.826087</td>\n",
              "      <td>0.868261</td>\n",
              "      <td>12.130435</td>\n",
              "      <td>186.869565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>11692.0</td>\n",
              "      <td>16031.629630</td>\n",
              "      <td>44.564815</td>\n",
              "      <td>3122.240741</td>\n",
              "      <td>2160.000000</td>\n",
              "      <td>1970.231481</td>\n",
              "      <td>4.321103e+05</td>\n",
              "      <td>49888.231481</td>\n",
              "      <td>11692</td>\n",
              "      <td>15848.375000</td>\n",
              "      <td>6.489142e+07</td>\n",
              "      <td>40.591584</td>\n",
              "      <td>-73.795186</td>\n",
              "      <td>169.833333</td>\n",
              "      <td>1.645833</td>\n",
              "      <td>43.166667</td>\n",
              "      <td>1.399583</td>\n",
              "      <td>1.895833</td>\n",
              "      <td>215.354167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>11693.0</td>\n",
              "      <td>15752.440000</td>\n",
              "      <td>32.546667</td>\n",
              "      <td>3252.093333</td>\n",
              "      <td>1637.600000</td>\n",
              "      <td>1937.360000</td>\n",
              "      <td>4.633523e+05</td>\n",
              "      <td>58453.146667</td>\n",
              "      <td>11693</td>\n",
              "      <td>17465.551724</td>\n",
              "      <td>7.201716e+07</td>\n",
              "      <td>40.587337</td>\n",
              "      <td>-73.814196</td>\n",
              "      <td>145.827586</td>\n",
              "      <td>4.724138</td>\n",
              "      <td>40.965517</td>\n",
              "      <td>1.519655</td>\n",
              "      <td>1.241379</td>\n",
              "      <td>175.793103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>11694.0</td>\n",
              "      <td>16245.225000</td>\n",
              "      <td>33.350000</td>\n",
              "      <td>4599.366667</td>\n",
              "      <td>2249.316667</td>\n",
              "      <td>1939.541667</td>\n",
              "      <td>8.011593e+05</td>\n",
              "      <td>59937.658333</td>\n",
              "      <td>11694</td>\n",
              "      <td>16738.166667</td>\n",
              "      <td>6.947310e+07</td>\n",
              "      <td>40.573405</td>\n",
              "      <td>-73.855335</td>\n",
              "      <td>226.500000</td>\n",
              "      <td>1.833333</td>\n",
              "      <td>14.333333</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.166667</td>\n",
              "      <td>285.666667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>173 rows Ã— 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     ZIPCODE         BLOCK  ...  calculated_host_listings_count  availability_365\n",
              "0    10001.0    786.227273  ...                        8.490566        131.898113\n",
              "1    10002.0    354.862069  ...                        1.789141         86.381313\n",
              "2    10003.0    684.312500  ...                        3.068285         78.286798\n",
              "3    10004.0     19.500000  ...                        4.448276         92.517241\n",
              "4    10005.0     34.400000  ...                       23.662338        138.636364\n",
              "..       ...           ...  ...                             ...               ...\n",
              "168  11436.0  12034.017094  ...                        1.733333        167.866667\n",
              "169  11691.0  15704.149606  ...                       12.130435        186.869565\n",
              "170  11692.0  16031.629630  ...                        1.895833        215.354167\n",
              "171  11693.0  15752.440000  ...                        1.241379        175.793103\n",
              "172  11694.0  16245.225000  ...                        1.166667        285.666667\n",
              "\n",
              "[173 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlvhiaJ2ER7R",
        "colab_type": "text"
      },
      "source": [
        "After the join, the columns might be confusing. Rename the two columns that we are interested in to: \n",
        "'Zillow_GROSS_SQUARE_FEET' and 'Airbnb_price'. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egr36TSzoi5s",
        "colab_type": "text"
      },
      "source": [
        "Submit the correlation matrix to the autograder \n",
        "(5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBXmVlggd3Fc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Penn grader entry\n",
        "grader.grade(test_case_id = 'corr_mat', answer = correlation_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWRRlGRnetav",
        "colab_type": "text"
      },
      "source": [
        "Here we provide code for you to visualize the correlation matrix. In the following code snippet below, please assign your correlation matrix to the variable named \"corr\" and then run the cell. You should see a correlation matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCQjctyGeJQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(style=\"white\")\n",
        "\n",
        "# Generate a large random dataset\n",
        "rs = np.random.RandomState(33)\n",
        "d = pd.DataFrame(data=rs.normal(size=(100, 26)),\n",
        "                 columns=list(ascii_letters[26:]))\n",
        "\n",
        "# Compute the correlation matrix\n",
        "#ASSIGN THE \"corr\" VARIABLE TO YOUR CORRELATION MATRIX\n",
        "corr = correlation_matrix\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.zeros_like(corr, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
        "plt.title(\"Correlation Heatmap: Airbnb & Zillow Data\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaomiQJhvhwI",
        "colab_type": "text"
      },
      "source": [
        "##4.2 Joining columns on roughly similar data\n",
        "\n",
        "**This problem is pretty difficult conceptually. But if my dumb self can get into this school, I know you can do this. Don't get discouraged! Ask questions on Piazza/come to OH!**\n",
        "\n",
        "There will be times when you have similar (but not exact) data between columns that you would like to join on. Convential joins, like the one you did above, will scan through each of the specified join columns, and find **exact** matches to establish that the rows from the associated datasets can be combined together into one row. But what happens if the join operation sees \"Mr.Smith\" in one dataset versus \"Mr Smith\"? It will skip over and think these two entries can't be joined even though there is a minor difference and the two values should be matched. This is where we combine n-grams with Jaccard Simalirty.\n",
        "\n",
        "This sounds scary but I'll break it down. An n-gram is a contiguous sequence of n items. An example would be given the sentence: \"Craig has a 2.2 GPA\" ... If we were looking at an n-gram of two, the results would be: [\"Craig has\", \"has a\", \"a 2.2\", \"2.2 GPA\"] (I swear my GPA isn't that. It's lower.)\n",
        "\n",
        "The above example is tokenizing/breaking up the n-grams by spaces. However, we can also do it characterwise. Given \"Craig has a 2.2 GPA\" with n-gram of 2 and doing characterwise splits, we will have: [\"Cr\", \"ra\", \"ai\", \"ig\", \" h\", \"ha\" ...]\n",
        "\n",
        "\n",
        "Jaccard similarity is a way to measure similarity between two sets. I recommend Googling around for more clarification but here is the notation for it: \n",
        "\n",
        "<p align = \"center\">\n",
        "<img src = \"https://i.ytimg.com/vi/Ah_4xqvS1WU/maxresdefault.jpg\" width= \"600\" align =\"center\"/>\n",
        "</p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epEhAzcy9G_y",
        "colab_type": "text"
      },
      "source": [
        "_________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e8owGlf8jwE",
        "colab_type": "text"
      },
      "source": [
        "We will focus on the \"NEIGHBORHOOD\" column in zillow_df and the \"neighbourhood\" in airbnb_df. If you take a look, these two columns share the same type of information but are formatted differently (i.e. \"UPPER WEST SIDE (59-79)\" in zillow_df versus \"Upper West Side\" in airbnb_df. We know these columns mean very similar things but merge/join operations don't. A possibility is to clean that column so that the formats match. But what if you have a ton of entries and you can't possibly account for everything?\n",
        "\n",
        "Our goal here is to join the neighbourhood columns without having to perform extensive cleaning operations in one of the columns.\n",
        "\n",
        "This can be broken down into:\n",
        "\n",
        "1. Take your zillow_df NEIGHBORHOOD column and lowercase all the entries except the first entry (aka capitalize). We do this to make the neighborhood columns between the two datasets as similar as possible without needing extensive cleaning.\n",
        "\n",
        "2. Define a Tokenizer with 5 grams. We have already imported our recommended library to do this at the top. I suggest looking at this for how to define a tokenzier: http://anhaidgroup.github.io/py_stringmatching/v0.2.x/QgramTokenizer.html\n",
        "\n",
        "3. Do a jaccard join. Again, we have already imported our recommended library for doing this at the top. Look here for documentaiton on how to do it: http://anhaidgroup.github.io/py_stringsimjoin/v0.1.x/api/jaccard_join.html ... When calling this function, set the l_out_attrs and r_out_attrs parameters to their associated table's neighbourhood column so that we keep those columns as we want to see our join results\n",
        "\n",
        "4. When selecting the tolerance, play around with some values between .1 < x < .4 to see what the join thinks could be joinable\n",
        "\n",
        "5. Drop duplicates from your jaccard-joined dataframe based on both neighbourhood columns as you will have a lot of duplicates. In other words, you might have 100+ entries of [\"MURRAY HILL\", \"MURRAY HILL\"]. We only want one entry for this.\n",
        "\n",
        "Name your answer to this section: \"answer_df\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz5tD0iQvh7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO\n",
        "answer_df = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-whqsZ7YCYD7",
        "colab_type": "text"
      },
      "source": [
        "Find a row entry in this dataframe where the airbnb and zillow neighborhoods aren't the same but are similar (i.e \"Clinton\" vs \"Clinton Hill\" or \"Mill basin\" vs \"Mill Basin\". Assign (You can manually type it out) the associated name to the following variables based on the dataset they originally belonged to.\n",
        "\n",
        "When you submit your answer to the autograder, make it a tuple of (result dataframe from the join, airbnb_neighborhood, zillow_neighborhood). (14 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAMNRl7KCZIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "airbnb_neighborhood = \"\"\n",
        "zillow_neighborhood = \"\"\n",
        "\n",
        "answer = (answer_df, airbnb_neighborhood, zillow_neighborhood)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpiHPep81MoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Penn grader entry\n",
        "grader.grade(test_case_id = 'jaccard_join', answer = answer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRNdFcIYfl9s",
        "colab_type": "text"
      },
      "source": [
        "#Part 5 XPath\n",
        "###Brought to you by popular demand from students...\n",
        "\n",
        "So far, we've looked at data from Airbnb, Uber, and Zillow. What do Airbnb and Uber have in common? They both were/are unicorn startups! \n",
        "According to Wikipedia, a unicorn is a privately held startup company with a current valuation of US$1 billion or more. Important to know for if/when you recruit for jobs!\n",
        "\n",
        "Also, while we're on the topic of pandas and unicorns:\n",
        "\n",
        "<p align = \"center\">\n",
        "<img src = \"https://ih0.redbubble.net/image.470874856.3122/flat,750x,075,f-pad,750x1000,f8f8f8.jpg\" width= \"200\" align =\"center\"/>\n",
        "</p>\n",
        "\n",
        "Let's look into unicorn startup companies some more. Take a look at this wikpedia page that has a full list of unicorn startup companies. https://en.wikipedia.org/wiki/List_of_unicorn_startup_companies. <br>\n",
        "Uber is on the former unicorns list due to IPO and Airbnb is still considered a unicorn. \n",
        "\n",
        "\n",
        "Using this data, return a dataframe that has the top 50 unicorn companies by Valuation. Your dataframe should be \n",
        "1. In descending order by Valuation. \n",
        "2. Have exactly two columns, \"Company\" and \"Valuation\". \n",
        "\n",
        "Hint: The first row should be: Ant Financial, 150. \n",
        "\n",
        "There are many different ways to do this but we recommend trying it with XPath. P.S. If you come to OH for help, we will mostly only know how to do it using the XPath way. (9 points)\n",
        "\n",
        "Assign the answer of this section to a dataframe named: \"answer_df\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhTadSKAfmGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO\n",
        "answer_df = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v-zVSMLrYHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Penn grader entry\n",
        "grader.grade(test_case_id = 'xPath_test', answer = answer_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjD6jZO5ieAG",
        "colab_type": "text"
      },
      "source": [
        "You're done! You are now a master data wrangler. Yeehaw!\n",
        "\n",
        "<p align = \"center\">\n",
        "<img src = \"https://compendiumofcountries.org/wiki/images/6/68/Data_Wrangler_-_Gaucho.png\" width= \"200\" align =\"center\"/>\n",
        "</p>\n",
        "\n",
        "This image shows up on google images when you search for \"data wrangler\". "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydELAEzkzpE_",
        "colab_type": "text"
      },
      "source": [
        "# HW Submission\n",
        "\n",
        "The good news is you basically know the score you already got because of the autograder. \n",
        "**Double check that you have the correct PennID (all numbers) in the autograder**. \n",
        "\n",
        "However, we will still double check your notebook to check for plagarism. Again, do not cheat. Go to the \"File\" tab at the top left, and click \"Download .ipynb\". Zip it (name shouldn't matter) and submit it to OpenSubmit. \n",
        "\n",
        "You must submit your notebook to receive credit.\n",
        "\n",
        "**On OpenSubmit, go to Settings and make sure to set your Student ID to your PennID (all numbers)**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKEKjKDJAHk3",
        "colab_type": "text"
      },
      "source": [
        "Lastly, enjoy this picture of what true love is\n",
        "\n",
        "<p align = \"center\">\n",
        "<img src = \"https://www.dataquest.io/wp-content/uploads/2019/01/6990634-panda-hug-832x520.jpg\" width= \"600\" align =\"center\"/>\n",
        "</p>"
      ]
    }
  ]
}